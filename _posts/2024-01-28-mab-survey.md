---
title: "Multi-armed Bandits with Bounded Rewards: A Short Survey"
date: 2024-01-28 24:00:00 -0700
category: Survey
comments: true
share: true
related: false
classes: wide
---

Here is a short survey covering the most commonly seen Multi-armed bandits (MAB) 
algorithms. You can download the full survey [here](/assets/survey-of-mab.pdf).