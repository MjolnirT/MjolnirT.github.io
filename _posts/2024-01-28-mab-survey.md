---
title: Multi-armed Bandits with Bounded Rewards a Short Survey
date: 2024-01-28 24:00:00 -0700
category: Survey
comments: true
share: true
related: false
classes: wide
---

Here is a short survey covering the most common seen Multi-armed bandits (MAB) 
algorithms. You can download the full survey [here](/assets/survey-of-mab.pdf).